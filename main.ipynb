{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "tokenTwitter = '44dbcc46f990445db65fab0d47adf939ef3d8695'\n",
        "\n",
        "config = {\n",
        "    'namaFile': 'dataset.csv',\n",
        "    'kataKunci': 'erupsi OR letusan OR lava OR magma OR lahar OR awan panas OR wedhus gembel OR piroklastik OR abu vulkanik OR kawah OR kaldera OR gempa vulkanik OR tremor OR vulkanik OR gunung api OR vulkanologi OR stratovolcano OR perisai OR magma asam OR magma basa OR kubah lava OR rekahan OR deformasi OR eksplosif OR efusif OR plinian OR freatik OR strombolian OR vulkanian OR bom vulkanik OR lapili OR lahar hujan OR lahar guguran OR gas vulkanik OR sulfur dioksida OR SO2 OR karbon dioksida OR CO2 OR status gunung api OR tingkat aktivitas OR siaga OR waspada OR awas OR normal OR pemantauan OR mitigasi OR evakuasi OR pengungsian OR jalur evakuasi OR kawasan rawan bencana OR kawasan rawan OR kawasan bahaya OR kawasan terlarang OR sirene OR peringatan dini OR shelter OR posko OR tanggap darurat OR bunker OR tanggul OR sabo OR dam pengaliran OR aliran piroklastik OR aliran lava OR guguran lava OR lontaran batu OR hujan abu OR jatuhan piroklastik OR kolom erupsi OR kolom abu OR kegempaan OR hiposentrum OR episentrum OR seismograf OR tiltmeter OR GPS OR DOAS OR solfatara OR fumarola OR mofet OR uap panas OR panas bumi OR kepundan OR dapur magma OR intrusi OR ekstrusi OR konduit OR vent OR semburan OR material piroklastik OR skoria OR tuf OR ignimbrit OR batuan vulkanik OR pasir vulkanik OR kerikil vulkanik OR boma apung OR litik OR juvenil OR kristal OR awan panas guguran OR awan panas aliran OR guguran kubah OR sector collapse OR jalur luncur OR longsor OR alur OR lembah OR weliras OR aliran lahar OR banjir lahar OR PVMBG OR badan mitigasi OR relokasi OR rehabilitasi OR pemulihan pasca OR pasca erupsi OR dampak erupsi OR gangguan pernapasan OR gangguan penerbangan OR gangguan pertanian OR infrastruktur rusak OR pembersihan abu OR kesiapsiagaan OR simulasi bencana OR danau kawah OR danau vulkanik OR awan asam OR vog OR aerosol vulkanik OR debu vulkanik OR jatuhan abu OR sebaran abu OR kubah gugur OR kubah rusak OR kubah aktif OR kubah tumbuh OR retakan tanah OR pembengkakan tanah OR penggembungan OR pengempisan OR inflasi OR deflasi OR desakan magma OR naik magma OR aktivitas magma OR sistem peringatan OR komunikasi bencana OR koordinasi OR logistik OR distribusi bantuan OR dapur umum OR kesehatan OR trauma OR psikososial OR evakuasi paksa OR evakuasi sukarela OR pos pantau OR pos pengamatan OR observasi visual OR observasi instrumental OR multiparameter OR peta bahaya OR zonasi bahaya OR kawasan aman OR kawasan cegat OR ancaman primer OR ancaman sekunder OR risiko bencana OR kajian risiko OR pemetaan ancaman OR perencanaan kontingensi OR skenario erupsi OR erupsi besar OR erupsi kecil OR erupsi berkala OR erupsi terus menerus OR fase erupsi OR puncak erupsi OR pasca puncak OR penurunan aktivitas OR aktivitas rendah OR istirahat OR dormant OR aktif OR mati OR extinct OR supervulkan OR megakaldera OR hotspot OR busur vulkanik OR subduksi OR lempeng tektonik OR vulkano tektonik OR aktivitas seismik OR aktivitas vulkanik OR prediksi erupsi OR peringatan evakuasi OR status evakuasi OR pos komando OR tim SAR OR pencarian OR penyelamatan OR korban jiwa OR luka luka OR pengungsi OR rumah rusak OR lahan tertutup OR abu tebal OR visibilitas rendah OR masker abu OR kacamata pelindung OR helm proyek OR alat pelindung diri OR jalur alternatif OR titik kumpul OR rumah aman OR hunian sementara OR tenda pengungsian OR air bersih OR makanan siap saji OR sanitasi OR MCK OR penyakit ISPA OR infeksi saluran pernapasan OR gangguan penglihatan OR iritasi kulit OR longsoran material OR aliran lumpur OR banjir bandang OR sedimentasi OR sungai meluap OR jembatan putus OR jalan terputus OR akses terhambat OR komunikasi terputus OR listrik padam OR suplai air OR gangguan transportasi OR penerbangan dibatalkan OR bandara ditutup OR ruang udara ditutup OR abu beterbangan OR abu tipis OR abu tebal OR abu halus OR abu kasar OR pasir letusan OR kerikil letusan OR batu letusan OR asap letusan OR asap putih OR asap kelabu OR asap hitam OR gempa harmonik OR gempa tremor OR gempa vulkanik dalam OR gempa vulkanik dangkal OR gempa frekuensi rendah OR gempa frekuensi tinggi OR amplitudo OR periode OR sinyal seismik OR jaringan seismometer OR stasiun pemantau OR kamera CCTV OR thermal camera OR kamera termal OR satelit penginderaan OR pengukuran gas OR pengukuran suhu OR pengukuran pH OR pengamatan visual harian OR laporan aktivitas OR rekomendasi teknis OR rekomendasi evakuasi OR status darurat OR keadaan darurat OR siaga satu OR siaga dua OR siaga tiga OR siaga empat OR status ancaman OR ancaman tinggi OR ancaman sedang OR ancaman rendah OR kawasan terdampak OR kawasan terancam OR warga terdampak OR warga mengungsi OR hewan ternak OR ternak mati OR pertanian gagal OR tanaman puso OR sawah tertutup OR kebun rusak OR hasil panen OR ekonomi lumpuh OR aktivitas warga OR aktivitas normal OR pemulihan ekonomi OR pemulihan sosial OR pemulihan lingkungan OR penghijauan kembali OR revegetasi OR suksesi ekologi OR ekosistem pulih OR kehidupan normal OR kembali pulih since:2018-01-01 until:2025-12-01 lang:id',\n",
        "    'limitTweets': 5000,\n",
        "    'tab': 'LATEST'\n",
        "}\n",
        "\n",
        "def installPkg():\n",
        "    subprocess.run(['apt-get', 'update'], check=False)\n",
        "\n",
        "    daftarPkg = [\n",
        "        'ca-certificates', 'curl', 'gnupg',\n",
        "        'libatk1.0-0', 'libatk-bridge2.0-0', 'libcups2',\n",
        "        'libxcomposite1', 'libxdamage1', 'libxfixes3',\n",
        "        'libxrandr2', 'libgbm1', 'libpango-1.0-0',\n",
        "        'libcairo2', 'libasound2'\n",
        "    ]\n",
        "\n",
        "    for pkg in daftarPkg:\n",
        "        subprocess.run(['apt-get', 'install', '-y', pkg], check=False)\n",
        "\n",
        "def installNode():\n",
        "    try:\n",
        "        perintah = [\n",
        "            ['mkdir', '-p', '/etc/apt/keyrings'],\n",
        "            ['bash', '-c', 'curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg'],\n",
        "            ['bash', '-c', 'echo \"deb [signed-by=//etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_20.x nodistro main\" | tee /etc/apt/sources.list.d/nodesource.list'],\n",
        "            ['apt-get', 'update'],\n",
        "            ['apt-get', 'install', 'nodejs', '-y']\n",
        "        ]\n",
        "\n",
        "        for cmd in perintah:\n",
        "            subprocess.run(cmd, check=False)\n",
        "\n",
        "        hasil = subprocess.run(['node', '-v'], capture_output=True, text=True)\n",
        "        print(f\"Node.js Terinstall: {hasil.stdout.strip()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error Instal Node.js: {e}\")\n",
        "\n",
        "def installPlaywright():\n",
        "    try:\n",
        "        subprocess.run(['npm', 'uninstall', '-g', 'playwright'], check=False)\n",
        "        subprocess.run(['npm', 'install', '-g', 'playwright'], check=False)\n",
        "        subprocess.run(['playwright', 'install', 'chromium'], check=False)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error Instal Playwright: {e}\")\n",
        "\n",
        "def ambilTweet():\n",
        "    print(f\"Mulai Ambil Tweet...\")\n",
        "    print(f\"Kata Kunci: {config['kataKunci']}\")\n",
        "    print(f\"Jumlah: {config['limitTweets']}\")\n",
        "    print(f\"File Output: {config['namaFile']}\")\n",
        "\n",
        "    perintah = [\n",
        "        'npx', '-y', 'tweet-harvest@2.6.1',\n",
        "        '-o', config['namaFile'],\n",
        "        '-s', config['kataKunci'],\n",
        "        '--tab', config['tab'],\n",
        "        '-l', str(config['limitTweets']),\n",
        "        '--token', tokenTwitter\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        hasil = subprocess.run(perintah, capture_output=True, text=True)\n",
        "\n",
        "        if hasil.returncode == 0:\n",
        "            print(\"Ambil Tweet Selesai.\")\n",
        "        else:\n",
        "            print(f\"Gagal Ambil Tweet: {hasil.stderr}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error Tweet-Harvest: {e}\")\n",
        "\n",
        "def main():\n",
        "    print(\"PROSES AMBIL TWEET\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    installPkg()\n",
        "    installNode()\n",
        "    installPlaywright()\n",
        "    ambilTweet()\n",
        "\n",
        "    print(\"\\nSELESAI!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "N-IzycJx_0Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/temp_group_1.csv')\n",
        "\n",
        "df['text'] = df['full_text']\n",
        "df['label'] = 1\n",
        "\n",
        "new_df = df[['text', 'label']]\n",
        "\n",
        "new_df.to_csv('dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "x_cTQ87-6JNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    text = str(text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub(r'RT\\s+', '', text)\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "df = pd.read_csv('new_file.csv')\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "\n",
        "df.to_csv('cleaned_file.csv', index=False)"
      ],
      "metadata": {
        "id": "A6fVCiva6Wff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "classifier = None\n",
        "vectorizer = None\n",
        "\n",
        "def load_data(filename):\n",
        "    global classifier, vectorizer\n",
        "\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    required_cols = ['text', 'label']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        print(\"Error: CSV harus punya kolom 'text' dan 'label'\")\n",
        "        return None\n",
        "\n",
        "    X = df['text']\n",
        "    y = df['label']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=3000, stop_words='english')\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
        "    classifier.fit(X_train_vec, y_train)\n",
        "\n",
        "    y_pred = classifier.predict(X_test_vec)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Akurasi model: {accuracy:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    model_data = {\n",
        "        'model': classifier,\n",
        "        'vectorizer': vectorizer\n",
        "    }\n",
        "    joblib.dump(model_data, 'tweet_classifier_model.pkl')\n",
        "    print(\"Model disimpan sebagai 'tweet_classifier_model.pkl'\")\n",
        "\n",
        "    return classifier\n",
        "\n",
        "def main():\n",
        "    filename = input(\"Masukkan nama file CSV dataset: \").strip()\n",
        "\n",
        "    try:\n",
        "        model = load_data(filename)\n",
        "        if model is not None:\n",
        "            print(\"Model berhasil dibuat dan disimpan.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{filename}' tidak ditemukan\")\n",
        "    except Exception as e:\n",
        "        print(f\"Terjadi error: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "-SwmiLDM6ive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def clear_screen():\n",
        "    os.system('cls' if os.name == 'nt' else 'clear')\n",
        "\n",
        "def load_model():\n",
        "    clear_screen()\n",
        "    try:\n",
        "        model_data = joblib.load('tweet_classifier_model.pkl')\n",
        "        classifier = model_data['model']\n",
        "        vectorizer = model_data['vectorizer']\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"MODEL BERHASIL DIMUAT\".center(60))\n",
        "        print(\"=\"*60)\n",
        "        input(\"\\nTekan Enter untuk melanjutkan...\")\n",
        "        clear_screen()\n",
        "        return classifier, vectorizer\n",
        "    except:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"PERINGATAN\".center(60))\n",
        "        print(\"=\"*60)\n",
        "        print(\"\\nâœ— Model 'tweet_classifier_model.pkl' tidak ditemukan\")\n",
        "        print(\"  Silakan train model terlebih dahulu\")\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        input(\"\\nTekan Enter untuk keluar...\")\n",
        "        clear_screen()\n",
        "        return None, None\n",
        "\n",
        "def predict_single_tweet(classifier, vectorizer, tweet):\n",
        "    clear_screen()\n",
        "    tweet_vec = vectorizer.transform([tweet])\n",
        "    prediction = classifier.predict(tweet_vec)[0]\n",
        "    probability = classifier.predict_proba(tweet_vec)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        label = \"GUNUNG MELETUS\"\n",
        "        label_symbol = \"ðŸŒ‹\"\n",
        "    else:\n",
        "        label = \"BUKAN GUNUNG MELETUS\"\n",
        "        label_symbol = \"âœ…\"\n",
        "\n",
        "    prob_volcano = probability[1]\n",
        "    prob_not = probability[0]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"HASIL PREDIKSI\".center(60))\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"\\nðŸ“ TWEET:\")\n",
        "    print(f\"   {tweet}\")\n",
        "\n",
        "    print(f\"\\nðŸ·ï¸  KATEGORI:\")\n",
        "    print(f\"   {label_symbol} {label}\")\n",
        "\n",
        "    print(f\"\\nðŸ“Š PROBABILITAS:\")\n",
        "    print(f\"   ðŸŒ‹ Gunung Meletus    : {prob_volcano:.2%}\")\n",
        "    print(f\"   âœ… Bukan            : {prob_not:.2%}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    input(\"\\nTekan Enter untuk kembali ke menu utama...\")\n",
        "    clear_screen()\n",
        "\n",
        "    return prediction, prob_volcano\n",
        "\n",
        "def predict_from_csv(classifier, vectorizer, csv_file):\n",
        "    clear_screen()\n",
        "    try:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"MEMPROSES FILE CSV\".center(60))\n",
        "        print(\"=\"*60)\n",
        "        print(f\"\\nðŸ“‚ Memuat file: {csv_file}\")\n",
        "\n",
        "        df = pd.read_csv(csv_file)\n",
        "\n",
        "        if 'text' not in df.columns:\n",
        "            print(\"\\nâœ— File CSV harus memiliki kolom 'text'\")\n",
        "            input(\"\\nTekan Enter untuk melanjutkan...\")\n",
        "            clear_screen()\n",
        "            return\n",
        "\n",
        "        tweets = df['text'].tolist()\n",
        "        tweets_vec = vectorizer.transform(tweets)\n",
        "\n",
        "        predictions = classifier.predict(tweets_vec)\n",
        "        probabilities = classifier.predict_proba(tweets_vec)\n",
        "\n",
        "        results = pd.DataFrame({\n",
        "            'text': tweets,\n",
        "            'prediction': predictions,\n",
        "            'category': ['GUNUNG MELETUS' if p == 1 else 'BUKAN' for p in predictions],\n",
        "            'prob_gunung_meletus': probabilities[:, 1],\n",
        "            'prob_bukan': probabilities[:, 0]\n",
        "        })\n",
        "\n",
        "        clear_screen()\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"HASIL PREDIKSI: {csv_file}\".center(60))\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for idx, row in results.iterrows():\n",
        "            print(f\"\\n{'â”€'*60}\")\n",
        "            print(f\"ðŸ“Š TWEET #{idx+1}\")\n",
        "            print(f\"{'â”€'*60}\")\n",
        "            print(f\"ðŸ“ {row['text'][:80]}...\" if len(row['text']) > 80 else f\"ðŸ“ {row['text']}\")\n",
        "            print(f\"ðŸ·ï¸  Kategori: {'ðŸŒ‹' if row['prediction'] == 1 else 'âœ…'} {row['category']}\")\n",
        "            print(f\"ðŸ“ˆ Probabilitas: {row['prob_gunung_meletus']:.2%}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"STATISTIK PREDIKSI\".center(60))\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        volcano_count = (results['prediction'] == 1).sum()\n",
        "        total_count = len(results)\n",
        "        volcano_percent = (volcano_count / total_count * 100) if total_count > 0 else 0\n",
        "\n",
        "        print(f\"\\nðŸ“ˆ TOTAL TWEET     : {total_count}\")\n",
        "        print(f\"ðŸŒ‹ GUNUNG MELETUS : {volcano_count} ({volcano_percent:.1f}%)\")\n",
        "        print(f\"âœ… BUKAN          : {total_count - volcano_count} ({100-volcano_percent:.1f}%)\")\n",
        "\n",
        "        results.to_csv('hasil_prediksi.csv', index=False)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ðŸ’¾ Hasil prediksi disimpan sebagai 'hasil_prediksi.csv'\".center(60))\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        input(\"\\nTekan Enter untuk kembali ke menu utama...\")\n",
        "        clear_screen()\n",
        "\n",
        "        return results\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\nâœ— File '{csv_file}' tidak ditemukan\")\n",
        "        input(\"\\nTekan Enter untuk melanjutkan...\")\n",
        "        clear_screen()\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâœ— Error: {str(e)}\")\n",
        "        input(\"\\nTekan Enter untuk melanjutkan...\")\n",
        "        clear_screen()\n",
        "\n",
        "def show_menu():\n",
        "    clear_screen()\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸŒ‹ SISTEM PREDIKSI TWEET GUNUNG MELETUS ðŸŒ‹\".center(60))\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nðŸ“‹ MENU UTAMA\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n1. ðŸ“ Prediksi Tweet Manual\")\n",
        "    print(\"2. ðŸ“ Prediksi dari File CSV\")\n",
        "    print(\"3. ðŸšª Keluar\")\n",
        "    print(\"\\n\" + \"â”€\"*60)\n",
        "\n",
        "    choice = input(\"ðŸ‘‰ Pilih menu (1/2/3): \").strip()\n",
        "    return choice\n",
        "\n",
        "def manual_prediction(classifier, vectorizer):\n",
        "    clear_screen()\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸ“ PREDIKSI TWEET MANUAL\".center(60))\n",
        "    print(\"=\"*60)\n",
        "    tweet = input(\"\\nMasukkan teks tweet:\\n\\n> \").strip()\n",
        "    if tweet:\n",
        "        predict_single_tweet(classifier, vectorizer, tweet)\n",
        "    else:\n",
        "        print(\"\\nâœ— Tweet tidak boleh kosong\")\n",
        "        input(\"\\nTekan Enter untuk melanjutkan...\")\n",
        "        clear_screen()\n",
        "\n",
        "def csv_prediction(classifier, vectorizer):\n",
        "    clear_screen()\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸ“ PREDIKSI DARI FILE CSV\".center(60))\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nðŸ“‹ Format file CSV:\")\n",
        "    print(\"   - Harus memiliki kolom 'text'\")\n",
        "    print(\"   - Setiap baris berisi satu tweet\")\n",
        "    print(\"\\nðŸ“ Contoh isi file:\")\n",
        "    print(\"   text\")\n",
        "    print(\"   \\\"gunung merapi erupsi malam ini\\\"\")\n",
        "    print(\"   \\\"hari ini cuaca cerah\\\"\")\n",
        "    print(\"\\n\" + \"â”€\"*60)\n",
        "\n",
        "    csv_file = input(\"\\nMasukkan nama file CSV:\\n\\n> \").strip()\n",
        "    if csv_file:\n",
        "        predict_from_csv(classifier, vectorizer, csv_file)\n",
        "    else:\n",
        "        print(\"\\nâœ— Nama file tidak boleh kosong\")\n",
        "        input(\"\\nTekan Enter untuk melanjutkan...\")\n",
        "        clear_screen()\n",
        "\n",
        "def main():\n",
        "    clear_screen()\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸŒ‹ SISTEM PREDIKSI TWEET GUNUNG MELETUS ðŸŒ‹\".center(60))\n",
        "    print(\"=\"*60)\n",
        "    input(\"\\nTekan Enter untuk memuat model...\")\n",
        "\n",
        "    classifier, vectorizer = load_model()\n",
        "\n",
        "    if classifier is None or vectorizer is None:\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        choice = show_menu()\n",
        "\n",
        "        if choice == '1':\n",
        "            manual_prediction(classifier, vectorizer)\n",
        "\n",
        "        elif choice == '2':\n",
        "            csv_prediction(classifier, vectorizer)\n",
        "\n",
        "        elif choice == '3':\n",
        "            clear_screen()\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"ðŸ‘‹ PROGRAM SELESAI\".center(60))\n",
        "            print(\"=\"*60)\n",
        "            input(\"\\nTekan Enter untuk keluar...\")\n",
        "            clear_screen()\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            clear_screen()\n",
        "            print(\"\\nâœ— Pilihan tidak valid. Silakan pilih 1, 2, atau 3.\")\n",
        "            input(\"\\nTekan Enter untuk melanjutkan...\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "9rK-6Oan6-2Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}